{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import e57\n",
    "import numpy as np\n",
    "import laspy\n",
    "\n",
    "# source = o3d.io.read_point_cloud(\"source.e57\")\n",
    "# target = o3d.io.read_point_cloud(\"target.pcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test(sou, **kwargs):\n",
    "    print(kwargs.keys())\n",
    "    print(kwargs['voxel_size'])\n",
    "    print(kwargs['distance_threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['voxel_size', 'distance_threshold'])\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "sample_test(11, voxel_size=10, distance_threshold=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_e57_as_pcd(pcd_path):\n",
    "    pcd_e57 = e57.read_points(pcd_path)\n",
    "\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(pcd_e57.points)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(pcd_e57.color)\n",
    "    return point_cloud\n",
    "\n",
    "def merge_e57_point_clouds(source_path, target_path, output_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Merge two overlapping .e57 point clouds into a single point cloud.\n",
    "\n",
    "    Args:\n",
    "        source_path (str): Path to the source .e57 file.\n",
    "        target_path (str): Path to the target .e57 file.\n",
    "        output_path (str): Path to save the merged point cloud as .e57 or other formats.\n",
    "\n",
    "    Returns:\n",
    "        merged_pcd (open3d.geometry.PointCloud): Merged point cloud.\n",
    "    \"\"\"\n",
    "    # Load source and target .e57 files\n",
    "    print(\"Loading point clouds...\")\n",
    "    \n",
    "    source_pcd = read_e57_as_pcd(source_path)\n",
    "    target_pcd = read_e57_as_pcd(target_path)\n",
    "    # source_pcd = o3d.io.read_point_cloud(source_path)\n",
    "    # target_pcd = o3d.io.read_point_cloud(target_path)\n",
    "\n",
    "    # Downsample point clouds for faster processing\n",
    "    print(\"Downsampling point clouds...\")\n",
    "    if kwargs['voxel_size'] is not None:\n",
    "        voxel_size = kwargs['voxel_size']\n",
    "    else:\n",
    "        voxel_size = 0.05  # Adjust voxel size as needed\n",
    "\n",
    "    if kwargs['distance_threshold'] is not None:\n",
    "        distance_threshold = kwargs['distance_threshold']\n",
    "    else:\n",
    "        distance_threshold = voxel_size * 2  # Adjust threshold as needed\n",
    "\n",
    "    source_down = source_pcd.voxel_down_sample(voxel_size)\n",
    "    target_down = target_pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    # Compute FPFH feature descriptors for both point clouds\n",
    "    print(\"Computing FPFH features...\")\n",
    "    source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        source_down, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100)\n",
    "    )\n",
    "    target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        target_down, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100)\n",
    "    )\n",
    "\n",
    "    # Perform RANSAC-based initial alignment\n",
    "    print(\"Performing initial alignment with RANSAC...\")\n",
    "    \n",
    "    result_ransac = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        ransac_n=4,\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(400000, 500)\n",
    "    )\n",
    "\n",
    "    print(\"Initial alignment result:\")\n",
    "    print(result_ransac)\n",
    "\n",
    "    # Perform fine-tuning with ICP\n",
    "    print(\"Refining alignment with ICP...\")\n",
    "    result_icp = o3d.pipelines.registration.registration_icp(\n",
    "        source_pcd, target_pcd, max_correspondence_distance=voxel_size,\n",
    "        init=result_ransac.transformation,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    )\n",
    "\n",
    "    print(\"ICP alignment result:\")\n",
    "    print(result_icp)\n",
    "\n",
    "    # Apply transformation to source point cloud\n",
    "    print(\"Applying transformation to source point cloud...\")\n",
    "    source_pcd.transform(result_icp.transformation)\n",
    "\n",
    "    # Merge the point clouds\n",
    "    print(\"Merging point clouds...\")\n",
    "    merged_pcd = source_pcd + target_pcd\n",
    "\n",
    "    # Save the merged point cloud\n",
    "    print(f\"Saving merged point cloud to {output_path}...\")\n",
    "    o3d.io.write_point_cloud(output_path, merged_pcd)\n",
    "\n",
    "    print(\"Point clouds merged successfully.\")\n",
    "    return merged_pcd\n",
    "\n",
    "def load_e57_to_o3d(filename):\n",
    "    \"\"\"\n",
    "    pye57를 사용하여 E57 파일에서 포인트 클라우드를 읽고,\n",
    "    Open3D의 PointCloud 객체로 변환하는 함수.\n",
    "    \"\"\"\n",
    "    # E57 파일 열기 (pye57 API는 다를 수 있음)\n",
    "    e57_file = e57.read(filename)\n",
    "    \n",
    "    # 예제에서는 get_points() 메서드를 통해 numpy 배열 (N x D)을 반환한다고 가정\n",
    "    # 첫 3열은 x, y, z 좌표, (옵션) 4~6열은 RGB 정보 (0~255 범위)\n",
    "    points_data = e57_file.get_points()  \n",
    "    # 예외 처리나 추가 전처리가 필요한 경우 여기에 추가\n",
    "    \n",
    "    # Open3D PointCloud 객체 생성\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    # 좌표 할당 (x,y,z)\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_data[:, :3])\n",
    "    \n",
    "    # RGB 정보가 있다면 (예: 컬럼 수가 6 이상)\n",
    "    if points_data.shape[1] >= 6:\n",
    "        # 0~255 범위를 0~1로 정규화하여 할당\n",
    "        colors = points_data[:, 3:6] / 255.0\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    \"\"\"\n",
    "    다운샘플링 및 노멀 추정 수행\n",
    "    \"\"\"\n",
    "    print(\":: Downsampling with voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "    print(\":: Estimating normals.\")\n",
    "    pcd_down.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2.0, max_nn=30))\n",
    "    return pcd_down\n",
    "\n",
    "def run_icp(source, target, voxel_size):\n",
    "    \"\"\"\n",
    "    o3d.pipelines.registration의 ICP를 사용한 정합 수행\n",
    "    \"\"\"\n",
    "    # 전처리: 다운샘플링 및 노멀 계산\n",
    "    source_down = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down = preprocess_point_cloud(target, voxel_size)\n",
    "    \n",
    "    # ICP 초기 매개변수\n",
    "    threshold = voxel_size * 1.5\n",
    "    trans_init = np.eye(4)\n",
    "    \n",
    "    print(\":: Running ICP registration.\")\n",
    "    reg_result = o3d.pipelines.registration.registration_icp(\n",
    "        source_down, target_down, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    \n",
    "    print(\":: ICP fitness:\", reg_result.fitness)\n",
    "    print(\":: ICP inlier RMSE:\", reg_result.inlier_rmse)\n",
    "    print(\":: Transformation:\\n\", reg_result.transformation)\n",
    "    print(\":: Transformation:\\n\", reg_result.transformation)\n",
    "    return reg_result.transformation\n",
    "\n",
    "def write_pcd2las(pcd, output_path):\n",
    "    # point_format 3는 RGB 정보를 포함하는 포맷 (LAS 1.4에서 지원)\n",
    "    header = laspy.LasHeader(point_format=3, version=\"1.4\")\n",
    "    # 좌표 값의 정밀도를 조정하기 위한 scale과 offset (데이터 범위에 맞게 조절)\n",
    "    header.scale = [0.001, 0.001, 0.001]\n",
    "    header.offset = [0, 0, 0]\n",
    "\n",
    "    # LAS 데이터 객체 생성\n",
    "    las = laspy.LasData(header)\n",
    "\n",
    "    # 좌표값 할당\n",
    "    las.x = np.asarray(pcd.points)[:,0]\n",
    "    las.y = np.asarray(pcd.points)[:,1]\n",
    "    las.z = np.asarray(pcd.points)[:,2]\n",
    "    las.red   = (np.asarray(pcd.colors)[:,0]*255.).astype(np.int8)\n",
    "    las.green = (np.asarray(pcd.colors)[:,1]*255.).astype(np.int8)\n",
    "    las.blue  = (np.asarray(pcd.colors)[:,2]*255.).astype(np.int8)\n",
    "    las.write(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voxel_size:다운샘플링 크기와 정렬의 정밀도에 영향을 미칩니다. 겹치는 영역이 작거나 더 세밀한 정렬이 필요할 경우 값을 줄이세요.\n",
    "\n",
    "distance_threshold:RANSAC 및 ICP 정렬 시의 대응점 거리 허용값. 겹치는 영역이 적다면 값을 늘려야 합니다.\n",
    "\n",
    "max_correspondence_distance: ICP의 대응점 거리 허용값으로, 병합 정밀도에 영향을 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "source_path = \"./../daeyoung/CustomPCD/(Test)LectureRoom2_1_cleaned.e57\"\n",
    "target_path = \"./../daeyoung/CustomPCD/(Test)LectureRoom2_2_cleaned.e57\"\n",
    "output_path = \"./../daeyoung/CustomPCD/(Test)LectureRoom2_merged.e57\"\n",
    "\n",
    "merged_pcd = merge_e57_point_clouds(source_path, target_path, output_path, voxel_size=10, distance_threshold=20)\n",
    "\n",
    "# # If overlapped points erased,\n",
    "# merged_pcd = merged_pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "# # Statistical noise removal\n",
    "# cl, ind = merged_pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
    "# merged_pcd = merged_pcd.select_by_index(ind)\n",
    "\n",
    "# Visualize the merged point cloud\n",
    "o3d.visualization.draw_geometries([merged_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper ones not work, here's new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_e57_to_o3d(filename):\n",
    "#     \"\"\"\n",
    "#     pye57를 사용하여 E57 파일에서 포인트 클라우드를 읽고,\n",
    "#     Open3D의 PointCloud 객체로 변환하는 함수.\n",
    "#     \"\"\"\n",
    "#     # E57 파일 열기 (pye57 API는 다를 수 있음)\n",
    "#     e57_file = e57.read(filename)\n",
    "    \n",
    "#     # 예제에서는 get_points() 메서드를 통해 numpy 배열 (N x D)을 반환한다고 가정\n",
    "#     # 첫 3열은 x, y, z 좌표, (옵션) 4~6열은 RGB 정보 (0~255 범위)\n",
    "#     points_data = e57_file.get_points()  \n",
    "#     # 예외 처리나 추가 전처리가 필요한 경우 여기에 추가\n",
    "    \n",
    "#     # Open3D PointCloud 객체 생성\n",
    "#     pcd = o3d.geometry.PointCloud()\n",
    "#     # 좌표 할당 (x,y,z)\n",
    "#     pcd.points = o3d.utility.Vector3dVector(points_data[:, :3])\n",
    "    \n",
    "#     # RGB 정보가 있다면 (예: 컬럼 수가 6 이상)\n",
    "#     if points_data.shape[1] >= 6:\n",
    "#         # 0~255 범위를 0~1로 정규화하여 할당\n",
    "#         colors = points_data[:, 3:6] / 255.0\n",
    "#         pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "#     return pcd\n",
    "\n",
    "# def preprocess_point_cloud(pcd, voxel_size):\n",
    "#     \"\"\"\n",
    "#     다운샘플링 및 노멀 추정 수행\n",
    "#     \"\"\"\n",
    "#     print(\":: Downsampling with voxel size %.3f.\" % voxel_size)\n",
    "#     pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "#     print(\":: Estimating normals.\")\n",
    "#     pcd_down.estimate_normals(\n",
    "#         search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2.0, max_nn=30))\n",
    "#     return pcd_down\n",
    "\n",
    "# def run_icp(source, target, voxel_size):\n",
    "#     \"\"\"\n",
    "#     o3d.pipelines.registration의 ICP를 사용한 정합 수행\n",
    "#     \"\"\"\n",
    "#     # 전처리: 다운샘플링 및 노멀 계산\n",
    "#     source_down = preprocess_point_cloud(source, voxel_size)\n",
    "#     target_down = preprocess_point_cloud(target, voxel_size)\n",
    "    \n",
    "#     # ICP 초기 매개변수\n",
    "#     threshold = voxel_size * 1.5\n",
    "#     trans_init = np.eye(4)\n",
    "    \n",
    "#     print(\":: Running ICP registration.\")\n",
    "#     reg_result = o3d.pipelines.registration.registration_icp(\n",
    "#         source_down, target_down, threshold, trans_init,\n",
    "#         o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    \n",
    "#     print(\":: ICP fitness:\", reg_result.fitness)\n",
    "#     print(\":: ICP inlier RMSE:\", reg_result.inlier_rmse)\n",
    "#     print(\":: Transformation:\\n\", reg_result.transformation)\n",
    "#     print(\":: Transformation:\\n\", reg_result.transformation)\n",
    "#     return reg_result.transformation\n",
    "\n",
    "# def write_pcd2las(pcd, output_path):\n",
    "#     # point_format 3는 RGB 정보를 포함하는 포맷 (LAS 1.4에서 지원)\n",
    "#     header = laspy.LasHeader(point_format=3, version=\"1.4\")\n",
    "#     # 좌표 값의 정밀도를 조정하기 위한 scale과 offset (데이터 범위에 맞게 조절)\n",
    "#     header.scale = [0.001, 0.001, 0.001]\n",
    "#     header.offset = [0, 0, 0]\n",
    "\n",
    "#     # LAS 데이터 객체 생성\n",
    "#     las = laspy.LasData(header)\n",
    "\n",
    "#     # 좌표값 할당\n",
    "#     las.x = np.asarray(pcd.points)[0]\n",
    "#     las.y = np.asarray(pcd.points)[1]\n",
    "#     las.z = np.asarray(pcd.points)[2]\n",
    "#     las.red   = np.asarray(pcd.colors)[0]\n",
    "#     las.green = np.asarray(pcd.colors)[1]\n",
    "#     las.blue  = np.asarray(pcd.colors)[2]\n",
    "#     las.write(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source point cloud from: ./../daeyoung/CustomPCD/(Test)LectureRoom2_1_cleaned.e57\n",
      "Loading target point cloud from: ./../daeyoung/CustomPCD/(Test)LectureRoom2_2_cleaned.e57\n",
      ":: Downsampling with voxel size 0.050.\n",
      ":: Estimating normals.\n",
      ":: Downsampling with voxel size 0.050.\n",
      ":: Estimating normals.\n",
      ":: Running ICP registration.\n",
      ":: ICP fitness: 0.9711419156004429\n",
      ":: ICP inlier RMSE: 0.015293299127615446\n",
      ":: Transformation:\n",
      " [[ 9.99999956e-01 -8.04108071e-05 -2.86265562e-04 -1.46346269e-02]\n",
      " [ 8.04230759e-05  9.99999996e-01  4.28469193e-05  3.82017844e-03]\n",
      " [ 2.86262115e-04 -4.28699397e-05  9.99999958e-01  2.75107145e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      ":: Transformation:\n",
      " [[ 9.99999956e-01 -8.04108071e-05 -2.86265562e-04 -1.46346269e-02]\n",
      " [ 8.04230759e-05  9.99999996e-01  4.28469193e-05  3.82017844e-03]\n",
      " [ 2.86262115e-04 -4.28699397e-05  9.99999958e-01  2.75107145e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "source_file = \"./../daeyoung/CustomPCD/(Test)LectureRoom2_1_cleaned.e57\"\n",
    "target_file = \"./../daeyoung/CustomPCD/(Test)LectureRoom2_2_cleaned.e57\"\n",
    "output_path = \"./../daeyoung/CustomPCD/(Test)LectureRoom2_merged.e57\"\n",
    "\n",
    "print(\"Loading source point cloud from:\", source_file)\n",
    "source_pcd = read_e57_as_pcd(source_file)\n",
    "\n",
    "print(\"Loading target point cloud from:\", target_file)\n",
    "target_pcd = read_e57_as_pcd(target_file)\n",
    "\n",
    "# registration을 위한 voxel 크기 설정 (데이터 특성에 따라 조절)\n",
    "voxel_size = 0.05  # 예: 5cm voxel\n",
    "\n",
    "# 두 포인트 클라우드 정합 수행\n",
    "transformation = run_icp(source_pcd, target_pcd, voxel_size)\n",
    "\n",
    "# 소스 PCD 변환환\n",
    "source_pcd.transform(transformation)\n",
    "\n",
    "#포인트 클라우드 합침\n",
    "merged_pcd = source_pcd + target_pcd\n",
    "# merged_pcd_down = merged_pcd.voxel_down_sample(voxel_size) ## If needed\n",
    "\n",
    "o3d.io.write_point_cloud(\"merged_point_cloud.ply\", merged_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pcd2las(merged_pcd, \"./../data/outputs/predPCDs/merged_point_cloud_LectureRoom.las\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
